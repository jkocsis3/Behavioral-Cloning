{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Used to train the model.\n",
    "# Fix error with TF and Keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "tf.python.control_flow_ops = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load .csv file\n",
      "(1140, 16, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Open the data from the files\n",
    "def LoadImages(log, index, cols, rows):\n",
    "    # print(log[index].split('/')[1])\n",
    "    # need to swap the / to a \\ for Windows.\n",
    "    #print(log[index].split('/')[1])\n",
    "    img = Image.open(\"./IMG/%s\" % log[index].split('/')[1])\n",
    "    img = np.array(img)\n",
    "    return cv2.resize(img, (cols, rows)) \n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "steeringAdjust = 0.3\n",
    "\n",
    "# open log file\n",
    "print(\"Load .csv file\")\n",
    "logs = []\n",
    "with open('driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        logs.append(row)\n",
    "\n",
    "for row in logs:\n",
    "    X.append(LoadImages(row, 0, 32, 16))\n",
    "    y.append(float(row[3]))\n",
    "    X.append(LoadImages(row, 1, 32, 16))\n",
    "    y.append(float(row[3]) + steeringAdjust)\n",
    "    X.append(LoadImages(row, 2, 32, 16))\n",
    "    y.append(float(row[3]) + steeringAdjust)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train totals (940, 16, 32, 3)\n",
      "Test totals (940, 16, 32, 3)\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0617599\n",
      "0.3617599\n",
      "0.3617599\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.3679529\n",
      "0.6679529\n",
      "0.6679529\n",
      "0.5784606\n",
      "0.8784606\n",
      "0.8784606\n",
      "0.5784606\n",
      "0.8784606\n",
      "0.8784606\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.08089697\n",
      "0.38089697\n",
      "0.38089697\n",
      "0.0904655\n",
      "0.3904655\n",
      "0.3904655\n",
      "0.0904655\n",
      "0.3904655\n",
      "0.3904655\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "-0.0787459\n",
      "0.2212541\n",
      "0.2212541\n",
      "-0.0787459\n",
      "0.2212541\n",
      "0.2212541\n",
      "-0.0787459\n",
      "0.2212541\n",
      "0.2212541\n",
      "-0.0787459\n",
      "0.2212541\n",
      "0.2212541\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.0904655\n",
      "0.3904655\n",
      "0.3904655\n",
      "0.38709\n",
      "0.68709\n",
      "0.68709\n",
      "0.3583844\n",
      "0.6583844\n",
      "0.6583844\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "-0.03127411\n",
      "0.26872589\n",
      "0.26872589\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "-0.04076847\n",
      "0.25923153\n",
      "0.25923153\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.2148564\n",
      "0.5148564\n",
      "0.5148564\n",
      "0.2148564\n",
      "0.5148564\n",
      "0.5148564\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "-0.08824026\n",
      "0.21175974\n",
      "0.21175974\n",
      "-0.2306556\n",
      "0.0693444\n",
      "0.0693444\n",
      "-0.2306556\n",
      "0.0693444\n",
      "0.0693444\n",
      "-0.1547008\n",
      "0.1452992\n",
      "0.1452992\n",
      "-0.0787459\n",
      "0.2212541\n",
      "0.2212541\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.04262284\n",
      "0.34262284\n",
      "0.34262284\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.1478767\n",
      "0.4478767\n",
      "0.4478767\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.2531306\n",
      "0.5531306\n",
      "0.5531306\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "-0.135712\n",
      "0.164288\n",
      "0.164288\n",
      "-0.2781274\n",
      "0.0218726\n",
      "0.0218726\n",
      "-0.3255992\n",
      "-0.0255992\n",
      "-0.0255992\n",
      "-0.2591387\n",
      "0.0408613\n",
      "0.0408613\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.03305431\n",
      "0.33305431\n",
      "0.33305431\n",
      "0.04262284\n",
      "0.34262284\n",
      "0.34262284\n",
      "0.0904655\n",
      "0.3904655\n",
      "0.3904655\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.243562\n",
      "0.543562\n",
      "0.543562\n",
      "0.2626991\n",
      "0.5626991\n",
      "0.5626991\n",
      "0.2626991\n",
      "0.5626991\n",
      "0.5626991\n",
      "0.2626991\n",
      "0.5626991\n",
      "0.5626991\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "-0.06925154\n",
      "0.23074846\n",
      "0.23074846\n",
      "-0.06925154\n",
      "0.23074846\n",
      "0.23074846\n",
      "-0.06925154\n",
      "0.23074846\n",
      "0.23074846\n",
      "-0.06925154\n",
      "0.23074846\n",
      "0.23074846\n",
      "-0.05975719\n",
      "0.24024281\n",
      "0.24024281\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.3488158\n",
      "0.6488158\n",
      "0.6488158\n",
      "0.3488158\n",
      "0.6488158\n",
      "0.6488158\n",
      "0.0904655\n",
      "0.3904655\n",
      "0.3904655\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "-0.1167233\n",
      "0.1832767\n",
      "0.1832767\n",
      "-0.1167233\n",
      "0.1832767\n",
      "0.1832767\n",
      "-0.1167233\n",
      "0.1832767\n",
      "0.1832767\n",
      "-0.1167233\n",
      "0.1832767\n",
      "0.1832767\n",
      "-0.09773462\n",
      "0.20226538\n",
      "0.20226538\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.02348577\n",
      "0.32348577\n",
      "0.32348577\n",
      "0.02348577\n",
      "0.32348577\n",
      "0.32348577\n",
      "0.0617599\n",
      "0.3617599\n",
      "0.3617599\n",
      "0.100034\n",
      "0.400034\n",
      "0.400034\n",
      "0.100034\n",
      "0.400034\n",
      "0.400034\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.01391724\n",
      "0.31391724\n",
      "0.31391724\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1574452\n",
      "0.4574452\n",
      "0.4574452\n",
      "0.1670138\n",
      "0.4670138\n",
      "0.4670138\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.1765823\n",
      "0.4765823\n",
      "0.4765823\n",
      "0.1478767\n",
      "0.4478767\n",
      "0.4478767\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.1287396\n",
      "0.4287396\n",
      "0.4287396\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.243562\n",
      "0.543562\n",
      "0.543562\n",
      "0.243562\n",
      "0.543562\n",
      "0.543562\n",
      "0.2339935\n",
      "0.5339935\n",
      "0.5339935\n",
      "0.243562\n",
      "0.543562\n",
      "0.543562\n",
      "0.2339935\n",
      "0.5339935\n",
      "0.5339935\n",
      "0.2148564\n",
      "0.5148564\n",
      "0.5148564\n",
      "0.0904655\n",
      "0.3904655\n",
      "0.3904655\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.0\n",
      "0.3\n",
      "0.3\n",
      "0.004348711\n",
      "0.304348711\n",
      "0.304348711\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.05219137\n",
      "0.35219137\n",
      "0.35219137\n",
      "0.05219137\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "# Load the data into training and test sets\n",
    "xTrain = X[:-200]\n",
    "yTrain = y[:-200]\n",
    "xTest = X[:-200]\n",
    "yTest = y[:-200]\n",
    "print(\"Train totals\", xTrain.shape)\n",
    "print(\"Test totals\", xTest.shape)\n",
    "for i in yTrain:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# One-Hot encode the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(yTrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (752, 16, 32, 3)\n",
      "Test (940, 16, 32, 3)\n",
      "validation (188, 16, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# split into train, test, validation\n",
    "xTrain, XValidation, yTrain, yValidation = train_test_split(xTrain, yTrain, test_size=0.2, random_state=0)\n",
    "print(\"Train\", xTrain.shape)\n",
    "print(\"Test\", xTest.shape)\n",
    "print(\"validation\", XValidation.shape)\n",
    "# shuffle the data\n",
    "xTrain, yTrain = shuffle(xTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features normalized\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Normalize the features\n",
    "print('features normalized')\n",
    "def normalize_grayscale(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + (((image_data - grayscale_min) * (b - a)) / (grayscale_max - grayscale_min))\n",
    "\n",
    "X_normalized = normalize_grayscale(xTrain)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 pool (None, 16, 15, 1)\n",
      "conv1 dropout (None, 16, 15, 1)\n",
      "conv1 activation (None, 16, 15, 1)\n",
      "Flatten (None, 240)\n",
      "FC1 (None, 128)\n",
      "FC1 Activation (None, 128)\n",
      "FC2 (None, 43)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(16, 32, 3)))\n",
    "# print('conv 1', model.output_shape)\n",
    "# Max pooling will cut your shape in 1/2\n",
    "model.add(MaxPooling2D((2, 2), dim_ordering='tf'))\n",
    "# print('conv1 pool',model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "# print('conv1 dropout',model.output_shape)\n",
    "model.add(Activation('relu'))\n",
    "# print('conv1 activation', model.output_shape)\n",
    "model.add(Flatten())\n",
    "# print('Flatten', model.output_shape)\n",
    "model.add(Dense(128))\n",
    "# print('FC1',model.output_shape)\n",
    "model.add(Activation('relu'))\n",
    "# print('FC1 Activation',model.output_shape)\n",
    "model.add(Dense(1))\n",
    "# print('FC2',model.output_shape)\n",
    "#model.add(Activation('softmax'))\n",
    "#print('FC 2 activation',model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error when checking model target: expected dense_14 to have shape (None, 43) but got array with shape (752, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e4f5fce2b58d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"begin training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1039\u001b[0m         \u001b[1;31m# prepare validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    965\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m    968\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m    969\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                         \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                                         \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                                         str(array.shape))\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model target: expected dense_14 to have shape (None, 43) but got array with shape (752, 1)"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'mean_squared_error', ['accuracy'])\n",
    "print(\"begin training\")\n",
    "history = model.fit(X_normalized, yTrain, nb_epoch=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Used to train the model.\n",
    "# Fix error with TF and Keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Convolution2D, Lambda\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "tf.python.control_flow_ops = tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load .csv file\n",
      "Images and labels loaded\n"
     ]
    }
   ],
   "source": [
    "cols = 32\n",
    "rows = 16\n",
    "# Open the data from the files\n",
    "def LoadImages(log, index, cols, rows):\n",
    "    # print(log[index].split('/')[1])\n",
    "    # need to swap the / to a \\ for Windows.\n",
    "    #print(log[index].split('/')[1])\n",
    "    img = Image.open(\"./IMG/%s\" % log[index].split('/')[1])\n",
    "    img = np.array(img)\n",
    "    return cv2.resize(img, (cols, rows))\n",
    "    # return cv2.resize(img, (cols, rows))\n",
    "\n",
    "    \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "steeringAdjust = 0.3\n",
    "\n",
    "# open log file\n",
    "print(\"Load .csv file\")\n",
    "logs = []\n",
    "with open('driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        logs.append(row)\n",
    "\n",
    "for row in logs:\n",
    "    X.append(LoadImages(row, 0, cols, rows))\n",
    "    y.append(float(row[3]))\n",
    "    X.append(LoadImages(row, 1, cols, rows))\n",
    "    y.append(float(row[3]) + steeringAdjust)\n",
    "    X.append(LoadImages(row, 2, cols, rows))\n",
    "    y.append(float(row[3]) + steeringAdjust)\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.concatenate([X, X[:,:,::-1]])\n",
    "y = np.concatenate([y, -y])\n",
    "print(\"Images and labels loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train totals (46216, 16, 32, 3)\n",
      "Test totals (16, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "# Load the data into training and test sets\n",
    "xTrain = X[:-2000]\n",
    "yTrain = y[:-2000]\n",
    "xTest = X[-2000]\n",
    "yTest = y[-2000]\n",
    "print(\"Train totals\", xTrain.shape)\n",
    "print(\"Test totals\", xTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([ 0. ,  0.3,  0.3, ..., -0.3, -0.3, -0. ]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-07bc64597672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m# One-Hot encode the labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel_binarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\envs\\python3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\envs\\python3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\envs\\python3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([ 0. ,  0.3,  0.3, ..., -0.3, -0.3, -0. ]),)"
     ]
    }
   ],
   "source": [
    "\n",
    "# One-Hot encode the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(yTrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (36972, 16, 32, 3)\n",
      "Test (16, 32, 3)\n",
      "validation (9244, 16, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train, test, validation\n",
    "xTrain, XValidation, yTrain, yValidation = train_test_split(xTrain, yTrain, test_size=0.2, random_state=0)\n",
    "print(\"Train\", xTrain.shape)\n",
    "print(\"Test\", xTest.shape)\n",
    "print(\"validation\", XValidation.shape)\n",
    "# shuffle the data\n",
    "xTrain, yTrain = shuffle(xTrain, yTrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features normalized\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('features normalized')\n",
    "\n",
    "\n",
    "def normalize_grayscale(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + (((image_data - grayscale_min) * (b - a)) / (grayscale_max - grayscale_min))\n",
    "\n",
    "\n",
    "X_normalized = normalize_grayscale(xTrain)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(16, 32, 3)))\n",
    "# print('conv 1', model.output_shape)\n",
    "# Max pooling will cut your shape in 1/2\n",
    "model.add(MaxPooling2D((2, 2), dim_ordering='tf'))\n",
    "# print('conv1 pool',model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "# print('conv1 dropout',model.output_shape)\n",
    "model.add(Activation('relu'))\n",
    "# print('conv1 activation', model.output_shape)\n",
    "model.add(Flatten())\n",
    "# print('Flatten', model.output_shape)\n",
    "model.add(Dense(128))\n",
    "# print('FC1',model.output_shape)\n",
    "model.add(Activation('relu'))\n",
    "# print('FC1 Activation',model.output_shape)\n",
    "model.add(Dense(1))\n",
    "# print('FC2',model.output_shape)\n",
    "#model.add(Activation('softmax'))\n",
    "#print('FC 2 activation',model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_6 (Convolution2D)  (None, 32, 30, 1)     4640        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 16, 15, 1)     0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 16, 15, 1)     0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 15, 1)     0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 240)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 128)           30848       flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 128)           0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             129         activation_2[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 35617\n",
      "____________________________________________________________________________________________________\n",
      "begin training\n",
      "Train on 29577 samples, validate on 7395 samples\n",
      "Epoch 1/40\n",
      "29577/29577 [==============================] - 12s - loss: 76.5674 - acc: 0.1559 - val_loss: 0.1711 - val_acc: 0.1763\n",
      "Epoch 2/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.1607 - acc: 0.1786 - val_loss: 0.1035 - val_acc: 0.1803\n",
      "Epoch 3/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.1087 - acc: 0.1804 - val_loss: 0.0866 - val_acc: 0.1815\n",
      "Epoch 4/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0930 - acc: 0.1809 - val_loss: 0.0819 - val_acc: 0.1822\n",
      "Epoch 5/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0844 - acc: 0.1813 - val_loss: 0.0802 - val_acc: 0.1822\n",
      "Epoch 6/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0822 - acc: 0.1815 - val_loss: 0.0788 - val_acc: 0.1823\n",
      "Epoch 7/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0802 - acc: 0.1816 - val_loss: 0.0784 - val_acc: 0.1823\n",
      "Epoch 8/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0802 - acc: 0.1816 - val_loss: 0.0782 - val_acc: 0.1824\n",
      "Epoch 9/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0795 - acc: 0.1816 - val_loss: 0.0780 - val_acc: 0.1824\n",
      "Epoch 10/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0793 - acc: 0.1816 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 11/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0796 - acc: 0.1816 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 12/40\n",
      "29577/29577 [==============================] - 14s - loss: 0.0792 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1823\n",
      "Epoch 13/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0797 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 14/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 15/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 16/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 17/40\n",
      "29577/29577 [==============================] - 13s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 18/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0795 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 19/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0792 - acc: 0.1817 - val_loss: 0.0796 - val_acc: 0.1823\n",
      "Epoch 20/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0802 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 21/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0792 - acc: 0.1817 - val_loss: 0.0780 - val_acc: 0.1824\n",
      "Epoch 22/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 23/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 24/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0780 - val_acc: 0.1824\n",
      "Epoch 25/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0792 - acc: 0.1817 - val_loss: 0.0780 - val_acc: 0.1824\n",
      "Epoch 26/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 27/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0780 - val_acc: 0.1824\n",
      "Epoch 28/40\n",
      "29577/29577 [==============================] - 13s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 29/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 30/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 31/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 32/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 33/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n",
      "Epoch 34/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 35/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 36/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 37/40\n",
      "29577/29577 [==============================] - 11s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 38/40\n",
      "29577/29577 [==============================] - 12s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 39/40\n",
      "29577/29577 [==============================] - 13s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0778 - val_acc: 0.1824\n",
      "Epoch 40/40\n",
      "29577/29577 [==============================] - 13s - loss: 0.0791 - acc: 0.1817 - val_loss: 0.0779 - val_acc: 0.1824\n"
     ]
    }
   ],
   "source": [
    "model.summary() # print model summary\n",
    "model.compile('adam', 'mean_squared_error', ['accuracy'])\n",
    "print(\"begin training\")\n",
    "history = model.fit(xTrain, yTrain, nb_epoch=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load .csv file\n",
      "Load training dataset\n",
      "#########\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Normalization (Lambda)           (None, 11, 32, 1)     0           lambda_input_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 2, 32, 1)      24          Normalization[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 2, 8, 1)       0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 2, 8, 1)       0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 16)            0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             17          flatten_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 41\n",
      "____________________________________________________________________________________________________\n",
      "Train on 43376 samples, validate on 4820 samples\n",
      "Epoch 1/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0792 - val_loss: 0.0698\n",
      "Epoch 2/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0639 - val_loss: 0.0498\n",
      "Epoch 3/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0488 - val_loss: 0.0349\n",
      "Epoch 4/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0399 - val_loss: 0.0285\n",
      "Epoch 5/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0362 - val_loss: 0.0275\n",
      "Epoch 6/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0348 - val_loss: 0.0263\n",
      "Epoch 7/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0351 - val_loss: 0.0267\n",
      "Epoch 8/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0344 - val_loss: 0.0257\n",
      "Epoch 9/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0345 - val_loss: 0.0261\n",
      "Epoch 10/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0343 - val_loss: 0.0254\n",
      "Epoch 11/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0340 - val_loss: 0.0260\n",
      "Epoch 12/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0341 - val_loss: 0.0253\n",
      "Epoch 13/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0342 - val_loss: 0.0254\n",
      "Epoch 14/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0336 - val_loss: 0.0258\n",
      "Epoch 15/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0339 - val_loss: 0.0259\n",
      "Epoch 16/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0342 - val_loss: 0.0256\n",
      "Epoch 17/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0341 - val_loss: 0.0255\n",
      "Epoch 18/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0338 - val_loss: 0.0255\n",
      "Epoch 19/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0339 - val_loss: 0.0256\n",
      "Epoch 20/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0338 - val_loss: 0.0255\n",
      "Epoch 21/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0340 - val_loss: 0.0251\n",
      "Epoch 22/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0341 - val_loss: 0.0246\n",
      "Epoch 23/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0338 - val_loss: 0.0259\n",
      "Epoch 24/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0339 - val_loss: 0.0251\n",
      "Epoch 25/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0337 - val_loss: 0.0251\n",
      "Epoch 26/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0339 - val_loss: 0.0259\n",
      "Epoch 27/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0339 - val_loss: 0.0254\n",
      "Epoch 28/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0338 - val_loss: 0.0251\n",
      "Epoch 29/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0337 - val_loss: 0.0256\n",
      "Epoch 30/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0338 - val_loss: 0.0258\n",
      "Epoch 31/40\n",
      "43376/43376 [==============================] - 2s - loss: 0.0338 - val_loss: 0.0255\n",
      "Epoch 32/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0339 - val_loss: 0.0255\n",
      "Epoch 33/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0342 - val_loss: 0.0260\n",
      "Epoch 34/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0337 - val_loss: 0.0263\n",
      "Epoch 35/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0338 - val_loss: 0.0253\n",
      "Epoch 36/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0340 - val_loss: 0.0262\n",
      "Epoch 37/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0339 - val_loss: 0.0253\n",
      "Epoch 38/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0339 - val_loss: 0.0257\n",
      "Epoch 39/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0336 - val_loss: 0.0255\n",
      "Epoch 40/40\n",
      "43376/43376 [==============================] - 1s - loss: 0.0336 - val_loss: 0.0250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2181c63ea90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
